{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3FA7uao+Bex3z71R4lJwc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rodoshi16/Fraud-transaction-detection-system-/blob/main/Data_prep_Fraud_detection_system_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5abjQ3dwvqy",
        "outputId": "44316399-d4b4-4893-9739-527d25222dde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1XWydcU314PzUnerMD-aznUHrDcwSKuqM\n",
            "From (redirected): https://drive.google.com/uc?id=1XWydcU314PzUnerMD-aznUHrDcwSKuqM&confirm=t&uuid=cb6dce09-10dc-4bab-bf84-b01d3c002548\n",
            "To: /content/creditcard.csv\n",
            "100%|██████████| 151M/151M [00:00<00:00, 195MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values per column:\n",
            "Time      0\n",
            "V1        0\n",
            "V2        0\n",
            "V3        0\n",
            "V4        0\n",
            "V5        0\n",
            "V6        0\n",
            "V7        0\n",
            "V8        0\n",
            "V9        0\n",
            "V10       0\n",
            "V11       0\n",
            "V12       0\n",
            "V13       0\n",
            "V14       0\n",
            "V15       0\n",
            "V16       0\n",
            "V17       0\n",
            "V18       0\n",
            "V19       0\n",
            "V20       0\n",
            "V21       0\n",
            "V22       0\n",
            "V23       0\n",
            "V24       0\n",
            "V25       0\n",
            "V26       0\n",
            "V27       0\n",
            "V28       0\n",
            "Amount    0\n",
            "Class     0\n",
            "dtype: int64\n",
            "Zero values per column:\n",
            "Time           2\n",
            "V1             0\n",
            "V2             0\n",
            "V3             0\n",
            "V4             0\n",
            "V5             0\n",
            "V6             0\n",
            "V7             0\n",
            "V8             0\n",
            "V9             0\n",
            "V10            0\n",
            "V11            0\n",
            "V12            0\n",
            "V13            0\n",
            "V14            0\n",
            "V15            0\n",
            "V16            0\n",
            "V17            0\n",
            "V18            0\n",
            "V19            0\n",
            "V20            0\n",
            "V21            0\n",
            "V22            0\n",
            "V23            0\n",
            "V24            0\n",
            "V25            0\n",
            "V26            0\n",
            "V27            0\n",
            "V28            0\n",
            "Amount      1825\n",
            "Class     284315\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-9d51646c6086>:37: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[['Amount', 'Time']] = scaler.fit_transform(df[['Amount', 'Time']])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original class distribution:\n",
            "Class\n",
            "0    283253\n",
            "1       473\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Resampled class distribution:\n",
            "Class\n",
            "0    198269\n",
            "1    198269\n",
            "Name: count, dtype: int64\n",
            "x_train_vec shape: (30, 30), y_train shape: (198608,)\n",
            "x_val_vec shape: (30, 30), y_val shape: (42559,)\n",
            "x_test_vec shape: (30, 30), y_test shape: (42559,)\n",
            "My dataset is clean and ready to go!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import gdown\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "file_id = \"1XWydcU314PzUnerMD-aznUHrDcwSKuqM\"\n",
        "output = 'creditcard.csv'\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "if not os.path.exists('data'):\n",
        "    os.makedirs('data')\n",
        "\n",
        "# reading the dataset\n",
        "df = pd.read_csv('creditcard.csv')\n",
        "\n",
        "\n",
        "print('Missing values per column:')\n",
        "print(df.isnull().sum())\n",
        "\n",
        "print(\"Zero values per column:\")\n",
        "print((df == 0).sum())\n",
        "\n",
        "# Dropping duplicate rows if any\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# In the dataset, time and Amount have different scales. ML models work\n",
        "# best when they have a similar scale. Therefore, we normalize it.\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df[['Amount', 'Time']] = scaler.fit_transform(df[['Amount', 'Time']])\n",
        "\n",
        "\n",
        "# We need to separate input from output. The values stored in class represent if\n",
        "# it's a fraud transaction or not. We need to store this as y for testing.\n",
        "\n",
        "# we want all the features except for class to use to predict fraud\n",
        "X = df.drop(columns=['Class'])\n",
        "y = df['Class']\n",
        "\n",
        "# we need to break the data into training and testing sets\n",
        "# 70% of the data is used to train the model through X_train and y_train\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Second split: 50% validation, 50% test from the temp set (because 50% of 30% = 15% each)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
        "\n",
        "\n",
        "# My dataset is highly imbalanced :(\n",
        "# When I parsed out the number of fraud cases vs not: its 492/ 284315 (normal data)\n",
        "# Now there should be equal representation of the data\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"\\nOriginal class distribution:\")\n",
        "print(y.value_counts())\n",
        "\n",
        "print(\"\\nResampled class distribution:\")\n",
        "print(pd.Series(y_train_resampled).value_counts())\n",
        "\n",
        "print(f\"x_train_vec shape: {x_train_vec.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"x_val_vec shape: {X_val_vec.shape}, y_val shape: {y_val.shape}\")\n",
        "print(f\"x_test_vec shape: {X_test_vec.shape}, y_test shape: {y_test.shape}\")\n",
        "\n",
        "# Cleaned dataset - yay!!!\n",
        "\n",
        "# X_train_resampled.to_csv('X_train_cleaned.csv', index=False)\n",
        "# y_train_resampled.to_csv('y_train_cleaned.csv', index=False)\n",
        "# X_test.to_csv('X_test_cleaned.csv', index=False)\n",
        "# y_test.to_csv('y_test_cleaned.csv', index=False)\n",
        "\n",
        "print('My dataset is clean and ready to go!')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_resampled, y_train_resampled)\n",
        "y_pred = model.predict(X_val)\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "conf_matrix = confusion_matrix(y_val, y_pred)\n",
        "print(f\"Validation Accuracy: {accuracy}\")\n",
        "print(f\"Confusion Matrix: \\n{conf_matrix}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p98I3bLUCSzm",
        "outputId": "7e0ac92f-9485-4743-c457-5c1e0da45481"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.975093399750934\n",
            "Confusion Matrix: \n",
            "[[41441  1052]\n",
            " [    8    58]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8WGapss7L6eo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}